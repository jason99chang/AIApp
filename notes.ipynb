{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    COUNTY  total_homes_sold  median_sale_price  median_sale_ppsf  \\\n",
      "4     1315              44.0           283500.0        161.276224   \n",
      "5     1315             471.0           283799.7        152.768580   \n",
      "6     1315             180.0           286875.0        157.181841   \n",
      "49    1315              79.0           287000.0        151.975684   \n",
      "50    1315             510.0           282091.6        153.066718   \n",
      "\n",
      "    price_drops  percent_active_listings_with_price_drops  \\\n",
      "4          19.0                                  0.027182   \n",
      "5          13.0                                  0.020966   \n",
      "6          17.0                                  0.025415   \n",
      "49         19.0                                  0.026135   \n",
      "50         14.0                                  0.021709   \n",
      "\n",
      "    median_days_to_close  pending_sales  inventory  median_active_list_price  \\\n",
      "4                   44.5           46.0      639.0                  350000.0   \n",
      "5                   41.5           40.0      591.0                  344605.5   \n",
      "6                   43.3           49.0      614.0                  349499.7   \n",
      "49                  44.0           52.0      660.0                  349900.0   \n",
      "50                  41.9           42.0      597.0                  345438.9   \n",
      "\n",
      "    median_active_list_ppsf  median_days_on_market  months_of_supply  \\\n",
      "4                158.410390                   34.5         15.886364   \n",
      "5                156.644721                   51.9         18.000316   \n",
      "6                157.192051                   33.0         16.738928   \n",
      "49               157.345679                   21.0          9.202532   \n",
      "50               156.689230                   47.3         17.435944   \n",
      "\n",
      "    total_homes_sold_with_price_drops  percent_homes_sold_with_price_drops  \\\n",
      "4                                 7.0                             0.159091   \n",
      "5                                90.0                             0.197403   \n",
      "6                                31.0                             0.179696   \n",
      "49                               10.0                             0.126582   \n",
      "50                               90.0                             0.187118   \n",
      "\n",
      "    average_of_median_offer_price_amount  average_sale_to_list_ratio  \\\n",
      "4                              497350.00                    0.992234   \n",
      "5                              429793.75                    0.985682   \n",
      "6                              400587.50                    0.986447   \n",
      "49                             405000.00                    0.992750   \n",
      "50                             435668.75                    0.988060   \n",
      "\n",
      "    percent_homes_sold_above_list  age_of_inventory  median_pending_sqft  \n",
      "4                        0.227273              52.0               2040.0  \n",
      "5                        0.187211              74.5               1920.5  \n",
      "6                        0.202693              56.3               2007.0  \n",
      "49                       0.240506              51.5               1926.0  \n",
      "50                       0.194753              70.1               1915.7  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "chunksize = 10 ** 4  # adjust this value depending on your available memory\n",
    "chunks = []\n",
    "\n",
    "selected_features = [\n",
    "    \"COUNTY\",\n",
    "    \"total_homes_sold\",\n",
    "    \"median_sale_price\",\n",
    "    \"median_sale_ppsf\",\n",
    "    \"price_drops\",\n",
    "    \"percent_active_listings_with_price_drops\",\n",
    "    \"median_days_to_close\",\n",
    "    \"pending_sales\",\n",
    "    \"inventory\",\n",
    "    \"median_active_list_price\",\n",
    "    \"median_active_list_ppsf\",\n",
    "    \"median_days_on_market\",\n",
    "    \"months_of_supply\",\n",
    "    \"total_homes_sold_with_price_drops\",\n",
    "    \"percent_homes_sold_with_price_drops\",\n",
    "    \"average_of_median_offer_price_amount\",\n",
    "    \"average_sale_to_list_ratio\",\n",
    "    \"percent_homes_sold_above_list\",\n",
    "    \"age_of_inventory\",\n",
    "    \"median_pending_sqft\",\n",
    "    #\"month\" Assuming you've created this feature from \"period_begin\" or \"period_end\"\n",
    "]\n",
    "\n",
    "for chunk in pd.read_csv('housingdata.tsv', delimiter='\\t', chunksize=chunksize):\n",
    "    # process the chunk, for example, filter rows or columns\n",
    "    filtered_chunk = chunk[selected_features]\n",
    "    chunks.append(filtered_chunk)\n",
    "\n",
    "# Concatenate all chunks into one DataFrame\n",
    "df = pd.concat(chunks, axis=0)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3646956\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'region_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m df1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(df1_list)\n\u001b[1;32m     49\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(df1))\n\u001b[0;32m---> 50\u001b[0m df1_combined \u001b[39m=\u001b[39m df1\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mregion_name\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39magg({\n\u001b[1;32m     51\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmedian_sale_price\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     52\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmedian_sale_ppsf\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     53\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtotal_homes_sold\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     54\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mpercent_homes_sold_with_price_drops\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     55\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mprice_drops\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     56\u001b[0m     \u001b[39m'\u001b[39m\u001b[39minventory\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     57\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtotal_active_listings\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     58\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmedian_active_list_price\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     59\u001b[0m })\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(df1_combined))\n\u001b[1;32m     62\u001b[0m \u001b[39mprint\u001b[39m(df1\u001b[39m.\u001b[39mhead())\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8399\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8400\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8402\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8403\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8404\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8405\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8406\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8407\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8408\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8409\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8410\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[1;32m   8411\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8412\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8413\u001b[0m )\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    966\u001b[0m         obj,\n\u001b[1;32m    967\u001b[0m         keys,\n\u001b[1;32m    968\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    969\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    970\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    971\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    972\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[1;32m    973\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    976\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    977\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    889\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'region_name'"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_features1 = [\n",
    "    'COUNTY',\n",
    "    'median_sale_price',\n",
    "    'median_sale_ppsf',\n",
    "    'total_homes_sold',\n",
    "    'percent_homes_sold_with_price_drops',\n",
    "    'price_drops',\n",
    "    'inventory',\n",
    "    'total_active_listings',\n",
    "    'median_active_list_price',\n",
    "    #\"month\" Assuming you've created this feature from \"period_begin\" or \"period_end\"\n",
    "]\n",
    "\n",
    "selected_features2 = [\n",
    "    'PROPERTY TYPE',\n",
    "    'CITY',\n",
    "    'ZIP OR POSTAL CODE',\n",
    "    'BEDS',\n",
    "    'BATHS',\n",
    "    'SQUARE FEET',\n",
    "    'LOT SIZE',\n",
    "    'YEAR BUILT',\n",
    "    'HOA/MONTH',\n",
    "    'LATITUDE',\n",
    "    'LONGITUDE',\n",
    "    'PRICE',\n",
    "    'DAYS ON MARKET',\n",
    "]\n",
    "\n",
    "\n",
    "file1 = 'housingdata.tsv'  # Macro-level real estate data\n",
    "file2 = 'housingdata2.csv'  # Transaction-level real estate data\n",
    "geolocator = Nominatim(user_agent='my-real-estate-application321')\n",
    "chunk_size = 10000  # Adjust the chunk size as per your requirements\n",
    "\n",
    "# Load the first dataset (macro-level real estate data)\n",
    "df1_chunks = pd.read_csv(file1, sep='\\t', chunksize=chunk_size)\n",
    "df1_list = []\n",
    "\n",
    "for chunk in df1_chunks:\n",
    "    # Process each chunk (selecting desired features, renaming columns, etc.)\n",
    "    chunk_selected = chunk[selected_features1]\n",
    "    # Append the processed chunk to the list\n",
    "    df1_list.append(chunk_selected)\n",
    "\n",
    "# Concatenate all the processed chunks into a single DataFrame\n",
    "df1 = pd.concat(df1_list)\n",
    "\n",
    "print(len(df1))\n",
    "df1_combined = df1.groupby('COUNTY').agg({\n",
    "    'median_sale_price': 'mean',\n",
    "    'median_sale_ppsf': 'mean',\n",
    "    'total_homes_sold': 'sum',\n",
    "    'percent_homes_sold_with_price_drops': 'mean',\n",
    "    'price_drops': 'sum',\n",
    "    'inventory': 'mean',\n",
    "    'total_active_listings': 'sum',\n",
    "    'median_active_list_price': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(len(df1_combined))\n",
    "print(df1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 SALE TYPE  SOLD DATE              PROPERTY TYPE  \\\n",
      "0              MLS Listing        NaN  Single Family Residential   \n",
      "1              MLS Listing        NaN  Single Family Residential   \n",
      "2              MLS Listing        NaN                  Townhouse   \n",
      "3              MLS Listing        NaN  Single Family Residential   \n",
      "4              MLS Listing        NaN  Single Family Residential   \n",
      "..                     ...        ...                        ...   \n",
      "130  New Construction Plan        NaN  Single Family Residential   \n",
      "131  New Construction Plan        NaN  Single Family Residential   \n",
      "132  New Construction Plan        NaN  Single Family Residential   \n",
      "133  New Construction Plan        NaN  Single Family Residential   \n",
      "134  New Construction Plan        NaN  Single Family Residential   \n",
      "\n",
      "                ADDRESS      CITY STATE OR PROVINCE  ZIP OR POSTAL CODE  \\\n",
      "0       65 Lafayette St  Stafford                VA               22554   \n",
      "1        316 Decatur Rd  Stafford                VA               22554   \n",
      "2    1209 Creek Bank Dr  Stafford                VA               22554   \n",
      "3            7 Knoll Ct  Stafford                VA               22554   \n",
      "4      991 Coriander Ln  Stafford                VA               22554   \n",
      "..                  ...       ...               ...                 ...   \n",
      "130           Hemingway  Stafford                VA               22554   \n",
      "131               Avery  Stafford                VA               22554   \n",
      "132               ROWAN  Stafford                VA               22554   \n",
      "133             KAITLYN  Stafford                VA               22554   \n",
      "134            BUCHANAN  Stafford                VA               22554   \n",
      "\n",
      "      PRICE  BEDS  BATHS  ...         STATUS  NEXT OPEN HOUSE START TIME  \\\n",
      "0    760000   4.0    4.5  ...  Pre On-Market       June-24-2023 01:00 PM   \n",
      "1    369000   4.0    3.0  ...         Active                         NaN   \n",
      "2    542816   4.0    3.5  ...         Active                         NaN   \n",
      "3    849900   4.0    2.5  ...         Active                         NaN   \n",
      "4    695500   5.0    5.0  ...         Active                         NaN   \n",
      "..      ...   ...    ...  ...            ...                         ...   \n",
      "130  635990   4.0    2.5  ...         Active                         NaN   \n",
      "131  645990   3.0    2.5  ...         Active                         NaN   \n",
      "132  764900   4.0    3.5  ...         Active                         NaN   \n",
      "133  788900   4.0    3.5  ...         Active                         NaN   \n",
      "134  720900   4.0    2.5  ...         Active                         NaN   \n",
      "\n",
      "     NEXT OPEN HOUSE END TIME  \\\n",
      "0       June-24-2023 03:00 PM   \n",
      "1                         NaN   \n",
      "2                         NaN   \n",
      "3                         NaN   \n",
      "4                         NaN   \n",
      "..                        ...   \n",
      "130                       NaN   \n",
      "131                       NaN   \n",
      "132                       NaN   \n",
      "133                       NaN   \n",
      "134                       NaN   \n",
      "\n",
      "                                                   URL             SOURCE  \\\n",
      "0    https://www.redfin.com/VA/Stafford/65-Lafayett...         BRIGHT MLS   \n",
      "1    https://www.redfin.com/VA/Stafford/316-Decatur...         BRIGHT MLS   \n",
      "2    https://www.redfin.com/VA/Stafford/1209-Creek-...         BRIGHT MLS   \n",
      "3    https://www.redfin.com/VA/Stafford/7-Knoll-Ct-...         BRIGHT MLS   \n",
      "4    https://www.redfin.com/VA/Stafford/991-Coriand...         BRIGHT MLS   \n",
      "..                                                 ...                ...   \n",
      "130  https://www.redfin.com/VA/Stafford-Courthouse/...  NewHomeSource.com   \n",
      "131  https://www.redfin.com/VA/Stafford-Courthouse/...  NewHomeSource.com   \n",
      "132  https://www.redfin.com/VA/Stafford/Embrey-Mill...  NewHomeSource.com   \n",
      "133  https://www.redfin.com/VA/Stafford/Embrey-Mill...  NewHomeSource.com   \n",
      "134  https://www.redfin.com/VA/Stafford/Embrey-Mill...  NewHomeSource.com   \n",
      "\n",
      "               MLS#  FAVORITE INTERESTED   LATITUDE  LONGITUDE  \n",
      "0       VAST2021516         N          Y  38.448647 -77.415554  \n",
      "1       VAST2022172         N          Y  38.459160 -77.349693  \n",
      "2       VAST2022196         N          Y  38.467322 -77.426342  \n",
      "3       VAST2022098         N          Y  38.428992 -77.381227  \n",
      "4       VAST2022188         N          Y  38.441299 -77.437096  \n",
      "..              ...       ...        ...        ...        ...  \n",
      "130  Plan-231815768         N          Y  38.441233 -77.435424  \n",
      "131  Plan-231815767         N          Y  38.441233 -77.435424  \n",
      "132  Plan-232190516         N          Y  38.441065 -77.434384  \n",
      "133  Plan-232190515         N          Y  38.441065 -77.434384  \n",
      "134  Plan-232190514         N          Y  38.441065 -77.434384  \n",
      "\n",
      "[135 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the second dataset (real estate transactions)\n",
    "\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "df2_chunks = pd.read_csv(file2, sep=',', chunksize=chunk_size)\n",
    "df2_list = []\n",
    "\n",
    "for chunk in df2_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(file2, sep=',')\n",
    "df2_list = []\n",
    "df2['COUNTY'] = df2.apply(lambda row: geolocator.reverse((row['LATITUDE'], row['LONGITUDE'])).raw['address'].get('county').upper(), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['COUNTY'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1325/1039987548.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COUNTY'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COUNTY'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Join the datasets based on the index (COUNTY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_format_argument_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6008\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6009\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6012\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6015\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['COUNTY'] are in the columns\""
     ]
    }
   ],
   "source": [
    "df1_combined.set_index('COUNTY', inplace=True)\n",
    "df2.set_index('COUNTY', inplace=True)\n",
    "\n",
    "# Join the datasets based on the index (COUNTY)\n",
    "merged_data = df2.join(df1, how='left')\n",
    "\n",
    "# Reset the index to make COUNTY a regular column again\n",
    "merged_data.reset_index(inplace=True)\n",
    "\n",
    "# Print the merged dataset\n",
    "print(merged_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
